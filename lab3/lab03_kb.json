[
  {
    "id": "kb001",
    "title": "LLM — definicja",
    "content": "Large Language Model (LLM) to model generatywny uczony na dużych zbiorach tekstu do przewidywania kolejnych tokenów.",
    "tags": [
      "llm",
      "definicja"
    ]
  },
  {
    "id": "kb002",
    "title": "Token",
    "content": "Token to jednostka tekstu widziana przez model, często fragment słowa lub znak.",
    "tags": [
      "token",
      "podstawy"
    ]
  },
  {
    "id": "kb003",
    "title": "Okno kontekstu",
    "content": "Okno kontekstu to maksymalna liczba tokenów wejścia i wyjścia rozpatrywana jednocześnie.",
    "tags": [
      "kontekst",
      "limity"
    ]
  },
  {
    "id": "kb004",
    "title": "RAG — idea",
    "content": "RAG łączy wyszukiwanie w korpusie wiedzy z generacją, dostarczając modelowi kontekst.",
    "tags": [
      "rag",
      "retrieval"
    ]
  },
  {
    "id": "kb005",
    "title": "Function Calling",
    "content": "Model zwraca strukturę narzędzia i argumentów; backend wykonuje funkcję i składa odpowiedź.",
    "tags": [
      "tools",
      "function-calling"
    ]
  },
  {
    "id": "kb06",
    "title": "Koszty tokenów",
    "content": "Tokeny = koszt. Kontroluj max_new_tokens, cache’uj embeddingi i używaj krótszych kontekstów.",
    "tags": [
      "koszt",
      "optymalizacja"
    ]
  },
  {
    "id": "kb07",
    "title": "RAG - testowe",
    "content": "RAG łączy wyszukiwanie w korpusie wiedzy z generacją, dostarczając modelowi kontekst.",
    "tags": [
      "rag",
      "retrieval"
    ]
  }
]